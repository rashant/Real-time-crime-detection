{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3AdbpZFCRR0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gb4Fv7Ag-kwb"
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "SEQUENCE_LENGTH = 20\n",
    "DATASET_DIR = \"dataset\"\n",
    "CLASSES_LIST = os.listdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBu224OG-szz"
   },
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "        success, frame = video_reader.read() \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    video_reader.release()\n",
    "\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6MLp9PpDJ4-"
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "    \n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "\n",
    "        for file_name in files_list:\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "    \n",
    "    return features, labels, video_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckAYgSriJN_R",
    "outputId": "c4cd44ea-f745-43ed-8a6a-cdad724b5569"
   },
   "outputs": [],
   "source": [
    "features, labels, video_files_paths = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfcpuV6_Bd_T"
   },
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhkQjq1JJSO2"
   },
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.25, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8cDSpfXJXwx"
   },
   "outputs": [],
   "source": [
    "def create_convlstm_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    model.add(ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    \n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = \"sigmoid\"))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2D1CS2Z6Jkp5",
    "outputId": "9d7d2e7e-f950-4f5c-c88b-810dc7c92c33"
   },
   "outputs": [],
   "source": [
    "convlstm_model = create_convlstm_model()\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yxx_adaPr8Vf",
    "outputId": "e085819d-1200-4298-f142-072cf573ad40"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
    "convlstm_model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4,\n",
    "                                                     shuffle = True, validation_split = 0.2, \n",
    "                                                     callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74tGjokkmSHR",
    "outputId": "f4a69c15-dab9-481b-85a2-fe8c1b3460c3"
   },
   "outputs": [],
   "source": [
    "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLfnP_czYudN"
   },
   "outputs": [],
   "source": [
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "\n",
    "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "convlstm_model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrQnmVF7aZjQ"
   },
   "outputs": [],
   "source": [
    "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
    "\n",
    "    metric_value_1 = model_training_history.history[metric_name_1]\n",
    "    metric_value_2 = model_training_history.history[metric_name_2]\n",
    "\n",
    "    epochs = range(len(metric_value_1))\n",
    "\n",
    "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "tKABbscJblP_",
    "outputId": "ddf20607-62fc-433c-ef4a-207344b8baf4"
   },
   "outputs": [],
   "source": [
    "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "cTSpJP-bb7WV",
    "outputId": "7e4330dc-51dc-45bb-bf97-80053deaa3e1"
   },
   "outputs": [],
   "source": [
    "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Human Action Recogntion using CNN + LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
